{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac17bcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_search(doc_list,keyword):\n",
    "    #need to put empty variable\n",
    "    iterate=[]\n",
    "    #need to use enumerate to keep track of the iterations/count\n",
    "    for i,doc in enumerate(doc_list):\n",
    "        #remove empty space in between the words\n",
    "        #tokens=doc.split()\n",
    "        #print(tokens)\n",
    "        #remove notation like(,.) and make all the elements in list tokens lowercase\n",
    "        normalize=[token.strip(',.').lower() for token in tokens]\n",
    "        print(normalize)\n",
    "        #find keyword in the new normalize list (do not care if is in lower or uppercase)\n",
    "        if keyword.lower() in normalize:\n",
    "            iterate.append(i)\n",
    "    return iterate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eddab454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'a', 'term,', 'data', 'analytics', 'predominantly', 'refers', 'to', 'an', 'assortment', 'of', 'applications,', 'from', 'basic', 'business']\n",
      "['intelligence', '(BI),', 'reporting', 'and', 'online', 'analytical', 'processing', '(OLAP)', 'to', 'various', 'forms', 'of', 'advanced']\n",
      "['analytics.', 'In', 'that', 'sense,', \"it's\", 'similar', 'in', 'nature', 'to', 'business', 'analytics,', 'another', 'umbrella', 'term', 'for']\n",
      "['approaches', 'to', 'analyzing', 'data', '--', 'with', 'the', 'difference', 'that', 'the', 'latter', 'is', 'oriented', 'to', 'business', 'uses,', 'while']\n",
      "['data', 'analytics', 'has', 'a', 'broader', 'focus.', 'The', 'expansive', 'view', 'of', 'the', 'term', \"isn't\", 'universal,', 'though:', 'In', 'some']\n",
      "['cases,', 'people', 'use', 'data', 'analytics', 'specifically', 'to', 'mean', 'advanced', 'analytics,', 'treating', 'BI', 'as', 'a', 'separate']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0, 3, 4, 5]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_list=[\"As a term, data analytics predominantly refers to an assortment of applications, from basic business \",\n",
    "          \"intelligence (BI), reporting and online analytical processing (OLAP) to various forms of advanced\",\n",
    "         \"analytics. In that sense, it's similar in nature to business analytics, another umbrella term for \",\n",
    "         \"approaches to analyzing data -- with the difference that the latter is oriented to business uses, while \",\n",
    "         \"data analytics has a broader focus. The expansive view of the term isn't universal, though: In some \",\n",
    "         \"cases, people use data analytics specifically to mean advanced analytics, treating BI as a separate \"]\n",
    "\n",
    "keyword='data'\n",
    "\n",
    "word_search(doc_list,keyword)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de2f4588",
   "metadata": {},
   "source": [
    "## 1.Probability of the word “data” occurring in each line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7135b1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of finding \"data\" in each line: 66.66666666666666\n"
     ]
    }
   ],
   "source": [
    "Prob_keyword=len(word_search(doc_list,keyword))/len(doc_list)*100\n",
    "#number of elements in the word search/number of elements in doc_list\n",
    "print(f\"% of finding \\\"data\\\" in each line: {Prob_keyword}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb7d0ff",
   "metadata": {},
   "source": [
    "### 2.Finding Distribution of distinct words across the lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dd3a4063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct words:15 across 6 lines \n",
      "Mean of distinct words across all the words: 1.0 \n",
      "Mode of distinct words:cases, \n"
     ]
    }
   ],
   "source": [
    "import statistics as st\n",
    "\n",
    "def unique_word_search(doc_list):\n",
    "    for i,doc in enumerate(doc_list):\n",
    "        #remove empty space in between the words\n",
    "        tokens=doc.split()\n",
    "    unique=set(tokens)\n",
    "    print(f\"Number of distinct words:{len(unique)} across {len(doc_list)} lines \\nMean of distinct words across all the words: {len(unique)/len(tokens)} \\nMode of distinct words:{st.mode(tokens)} \")\n",
    "    \n",
    "unique_word_search(doc_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "682d8bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mod_word_search(doc_list,keyword1,keyword2):\n",
    "    #need to put empty variable\n",
    "    iterate=[]\n",
    "    #need to use enumerate to keep track of the iterations/count\n",
    "    for i,doc in enumerate(doc_list):\n",
    "        #remove empty space in between the words\n",
    "        tokens=doc.split()\n",
    "        print(tokens)\n",
    "        #remove notation like(,.) and make all the elements in list tokens lowercase\n",
    "        normalize=[token.strip(',.').lower() for token in tokens]\n",
    "        #find keyword in the new normalize list (do not care if is in lower or uppercase)\n",
    "        if keyword1.lower() not in normalize or keyword2.lower() not in normalize:\n",
    "            iterate=[]\n",
    "            \n",
    "        elif normalize.index(keyword1)>normalize.index(keyword2):\n",
    "            \n",
    "            iterate.append(i)\n",
    "    \n",
    "    \n",
    "    return iterate\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "830c5a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'a', 'term,', 'data', 'analytics', 'predominantly', 'refers', 'to', 'an', 'assortment', 'of', 'applications,', 'from', 'basic', 'business']\n",
      "['intelligence', '(BI),', 'reporting', 'and', 'online', 'analytical', 'processing', '(OLAP)', 'to', 'various', 'forms', 'of', 'advanced']\n",
      "['analytics.', 'In', 'that', 'sense,', \"it's\", 'similar', 'in', 'nature', 'to', 'business', 'analytics,', 'another', 'umbrella', 'term', 'for']\n",
      "['approaches', 'to', 'analyzing', 'data', '--', 'with', 'the', 'difference', 'that', 'the', 'latter', 'is', 'oriented', 'to', 'business', 'uses,', 'while']\n",
      "['data', 'analytics', 'has', 'a', 'broader', 'focus.', 'The', 'expansive', 'view', 'of', 'the', 'term', \"isn't\", 'universal,', 'though:', 'In', 'some']\n",
      "['cases,', 'people', 'use', 'data', 'analytics', 'specifically', 'to', 'mean', 'advanced', 'analytics,', 'treating', 'BI', 'as', 'a', 'separate']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[4, 5]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword1=\"analytics\"\n",
    "keyword2=\"data\"\n",
    "\n",
    "mod_word_search(doc_list,keyword1,keyword2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d49753c",
   "metadata": {},
   "source": [
    "## Probability of the word “analytics” occurring after the word “data” ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "41373a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['As', 'a', 'term,', 'data', 'analytics', 'predominantly', 'refers', 'to', 'an', 'assortment', 'of', 'applications,', 'from', 'basic', 'business']\n",
      "['intelligence', '(BI),', 'reporting', 'and', 'online', 'analytical', 'processing', '(OLAP)', 'to', 'various', 'forms', 'of', 'advanced']\n",
      "['analytics.', 'In', 'that', 'sense,', \"it's\", 'similar', 'in', 'nature', 'to', 'business', 'analytics,', 'another', 'umbrella', 'term', 'for']\n",
      "['approaches', 'to', 'analyzing', 'data', '--', 'with', 'the', 'difference', 'that', 'the', 'latter', 'is', 'oriented', 'to', 'business', 'uses,', 'while']\n",
      "['data', 'analytics', 'has', 'a', 'broader', 'focus.', 'The', 'expansive', 'view', 'of', 'the', 'term', \"isn't\", 'universal,', 'though:', 'In', 'some']\n",
      "['cases,', 'people', 'use', 'data', 'analytics', 'specifically', 'to', 'mean', 'advanced', 'analytics,', 'treating', 'BI', 'as', 'a', 'separate']\n",
      "% of finding \"analytics\" after \"data\"in each line: 33.33333333333333\n"
     ]
    }
   ],
   "source": [
    "Mod_Prob_keyword=len(mod_word_search(doc_list,keyword1,keyword2))/len(doc_list)*100\n",
    "#number of elements in the word search/number of elements in doc_list\n",
    "print(f\"% of finding \\\"analytics\\\" after \\\"data\\\"in each line: {Mod_Prob_keyword}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d58416d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
